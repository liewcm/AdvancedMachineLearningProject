{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5349,
     "status": "ok",
     "timestamp": 1733891835046,
     "user": {
      "displayName": "Liew Cheah Ming",
      "userId": "16761576291408548451"
     },
     "user_tz": -480
    },
    "id": "27phBOwQKDPz",
    "outputId": "fb4bc1cc-74c6-428d-ba34-ed4c405e3398"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Levenshtein\n",
      "  Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein)\n",
      "  Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Downloading levenshtein-0.26.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein\n",
      "Successfully installed Levenshtein-0.26.1 rapidfuzz-3.10.1\n"
     ]
    }
   ],
   "source": [
    "pip install Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 3632,
     "status": "ok",
     "timestamp": 1733891843922,
     "user": {
      "displayName": "Liew Cheah Ming",
      "userId": "16761576291408548451"
     },
     "user_tz": -480
    },
    "id": "NFRR03H5Jg-O"
   },
   "outputs": [],
   "source": [
    "\n",
    "import Levenshtein as Lev\n",
    "import torch\n",
    "\n",
    "\n",
    "class Decoder(object):\n",
    "    \"\"\"\n",
    "    Basic decoder class from which all other decoders inherit. Implements several\n",
    "    helper functions. Subclasses should implement the decode() method.\n",
    "\n",
    "    Arguments:\n",
    "        labels (list): mapping from integers to characters\n",
    "        blank_index (int, optional): index for the blank '_' character. Defaults to 0.\n",
    "        spece_index (int, optional): index for the space ' ' character. Defaults to 28.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, labels, blank_index=0):\n",
    "        self.labels = labels\n",
    "        self.int_to_char = dict([(i, c) for (i, c) in enumerate(labels)])\n",
    "        self.blank_index = blank_index\n",
    "        space_index = len(labels) # To prevent errors in decode, we add an out of bounds index for the space\n",
    "        if ' ' in labels:\n",
    "            space_index = labels.index(' ')\n",
    "        self.space_index = space_index\n",
    "\n",
    "    def wer(self, s1, s2):\n",
    "\n",
    "\n",
    "    # Tokenize the sentences into words\n",
    "         words1 = s1.split()\n",
    "         words2 = s2.split()\n",
    "\n",
    "    # Calculate the Levenshtein distance directly on word sequences\n",
    "         return Lev.distance(' '.join(words1), ' '.join(words2)) / float(len(words1) or 1)\n",
    "\n",
    "\n",
    "    def cer(self, s1, s2):\n",
    "        \"\"\"\n",
    "        Computes the character Error Rate, defined as the edit distace.\n",
    "\n",
    "        Arguments:\n",
    "            s1 (string): space-separated sentence\n",
    "            s2 (string): space-separated sentence\n",
    "        \"\"\"\n",
    "        s1, s2 = s1.replace(' ', ''), s2.replace(' ', '')\n",
    "        if len(s1) == 0 and len(s2) == 0:\n",
    "            return 0.0  # No error if both strings are empty\n",
    "        return Lev.distance(s1, s2)\n",
    "\n",
    "    def decode(self, probs, sizes=None):\n",
    "        \"\"\"\n",
    "        Given a matrix of character probabilities, returns the decoder's\n",
    "        best guess of the transcription\n",
    "        Arguments:\n",
    "            probs: Tensor of character probabilities, where probs[c,t]\n",
    "                            is the probability of character c at time t\n",
    "            sizes(optional): Size of each sequence in the mini-batch\n",
    "        Returns:\n",
    "            string: sequence of the model's best guess for the transcription\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "class BeamCTCDecoder(Decoder):\n",
    "    def __init__(self, labels, lm_path=None, alpha=0, beta=0, cutoff_top_n=40, cutoff_prob=1.0, beam_width=100, num_processes=4, blank_index=0):\n",
    "        super(BeamCTCDecoder, self).__init__(labels)\n",
    "        try:\n",
    "            from ctcdecode import CTCBeamDecoder\n",
    "        except ImportError:\n",
    "            raise ImportError(\"BeamCTCDecoder requires paddledecoder package.\")\n",
    "        labels = list(labels)  # Ensure labels are a list before passing to decoder\n",
    "        self._decoder = CTCBeamDecoder(labels, lm_path, alpha, beta, cutoff_top_n,  cutoff_prob, beam_width,\n",
    "                                       num_processes, blank_index)\n",
    "\n",
    "    def convert_to_strings(self, out, seq_len):\n",
    "        results = []\n",
    "        for b, batch in enumerate(out):\n",
    "            utterances = []\n",
    "            for p, utt in enumerate(batch):\n",
    "                size = seq_len[b][p]\n",
    "                if size > 0:\n",
    "                    transcript = ''.join(map(lambda x: self.int_to_char[x.item()], utt[0:size]))\n",
    "                else:\n",
    "                    transcript = ''\n",
    "                utterances.append(transcript)\n",
    "            results.append(utterances)\n",
    "        return results\n",
    "\n",
    "    def convert_tensor(self, offsets, sizes):\n",
    "        results = []\n",
    "        for b, batch in enumerate(offsets):\n",
    "            utterances = []\n",
    "            for p, utt in enumerate(offsets):\n",
    "                size = sizes[b][p]\n",
    "                if sizes[b][p] > 0:\n",
    "                    utterances.append(utt[0:size])\n",
    "                else:\n",
    "                    utterances.append(torch.tensor([], dtype=torch.int))\n",
    "            results.append(utterances)\n",
    "        return results\n",
    "\n",
    "    def decode(self, probs, sizes=None):\n",
    "        \"\"\"\n",
    "        Decodes probability output using ctcdecode package.\n",
    "        Arguments:\n",
    "            probs: Tensor of character probabilities, where probs[c,t]\n",
    "                            is the probability of character c at time t\n",
    "            sizes: Size of each sequence in the mini-batch\n",
    "        Returns:\n",
    "            string: sequences of the model's best guess for the transcription\n",
    "        \"\"\"\n",
    "        probs = probs.cpu()\n",
    "        out, scores, offsets, seq_lens = self._decoder.decode(probs, sizes)\n",
    "\n",
    "        strings = self.convert_to_strings(out, seq_lens)\n",
    "        offsets = self.convert_tensor(offsets, seq_lens)\n",
    "        return strings, offsets\n",
    "\n",
    "\n",
    "class GreedyDecoder(Decoder):\n",
    "    def __init__(self, labels, blank_index=0):\n",
    "        super(GreedyDecoder, self).__init__(labels, blank_index)\n",
    "\n",
    "    def convert_to_strings(self, sequences, sizes=None, remove_repetitions=False, return_offsets=False):\n",
    "        \"\"\"Given a list of numeric sequences, returns the corresponding strings\"\"\"\n",
    "        strings = []\n",
    "        offsets = [] if return_offsets else None\n",
    "        for x in range(len(sequences)):\n",
    "            seq_len = sizes[x] if sizes is not None else len(sequences[x])\n",
    "            string, string_offsets = self.process_string(sequences[x], seq_len, remove_repetitions)\n",
    "            strings.append([string])  # We only return one path\n",
    "            if return_offsets:\n",
    "                offsets.append([string_offsets])\n",
    "        if return_offsets:\n",
    "            return strings, offsets\n",
    "        else:\n",
    "            return strings\n",
    "\n",
    "    def process_string(self, sequence, size, remove_repetitions=False):\n",
    "        string = ''\n",
    "        offsets = []\n",
    "        for i in range(size):\n",
    "            char = self.int_to_char[sequence[i].item()]\n",
    "            if char != self.int_to_char[self.blank_index]:\n",
    "                # if this char is a repetition and remove_repetitions=true, then skip\n",
    "                if remove_repetitions and i != 0 and char == self.int_to_char[sequence[i - 1].item()]:\n",
    "                    pass\n",
    "                elif char == self.labels[self.space_index]:\n",
    "                    string += ' '\n",
    "                    offsets.append(i)\n",
    "                else:\n",
    "                    string = string + char\n",
    "                    offsets.append(i)\n",
    "        return string, torch.tensor(offsets, dtype=torch.int)\n",
    "\n",
    "    def decode(self, probs, sizes=None):\n",
    "        \"\"\"\n",
    "        Returns the argmax decoding given the probability matrix. Removes\n",
    "        repeated elements in the sequence, as well as blanks.\n",
    "        Arguments:\n",
    "            probs: Tensor of character probabilities from the network. Expected shape of batch x seq_length x output_dim\n",
    "            sizes(optional): Size of each sequence in the mini-batch\n",
    "        Returns:\n",
    "            strings: sequences of the model's best guess for the transcription on inputs\n",
    "            offsets: time step per character predicted\n",
    "        \"\"\"\n",
    "        _, max_probs = torch.max(probs, 2)\n",
    "        strings, offsets = self.convert_to_strings(max_probs.view(max_probs.size(0), max_probs.size(1)), sizes,\n",
    "                                                   remove_repetitions=True, return_offsets=True)\n",
    "        return strings, offsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10614,
     "status": "ok",
     "timestamp": 1733891859736,
     "user": {
      "displayName": "Liew Cheah Ming",
      "userId": "16761576291408548451"
     },
     "user_tz": -480
    },
    "id": "TYRkN6WOKk78",
    "outputId": "962e0291-2021-4f6f-bc15-73ca6321de3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [Working]\r",
      "            \r",
      "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
      "\r",
      "0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Connecting to security.ubuntu.com (91.189.91\r",
      "0% [Connecting to archive.ubuntu.com (185.125.190.81)] [Connecting to security.ubuntu.com (91.189.91\r",
      "                                                                                                    \r",
      "Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
      "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
      "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,194 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
      "Get:8 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,458 kB]\n",
      "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
      "Get:10 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,331 kB]\n",
      "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,627 kB]\n",
      "Get:12 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,226 kB]\n",
      "Get:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
      "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
      "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,537 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,751 kB]\n",
      "Get:18 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [49.7 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,515 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,475 kB]\n",
      "Fetched 27.6 MB in 2s (12.9 MB/s)\n",
      "Reading package lists... Done\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "libboost-all-dev is already the newest version (1.74.0.3ubuntu7).\n",
      "Suggested packages:\n",
      "  swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
      "The following NEW packages will be installed:\n",
      "  swig swig4.0\n",
      "0 upgraded, 2 newly installed, 0 to remove and 58 not upgraded.\n",
      "Need to get 1,116 kB of archives.\n",
      "After this operation, 5,542 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n",
      "Fetched 1,116 kB in 1s (1,221 kB/s)\n",
      "Selecting previously unselected package swig4.0.\n",
      "(Reading database ... 123632 files and directories currently installed.)\n",
      "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
      "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
      "Selecting previously unselected package swig.\n",
      "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
      "Unpacking swig (4.0.2-1ubuntu1) ...\n",
      "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
      "Setting up swig (4.0.2-1ubuntu1) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get update\n",
    "!apt-get install -y swig libboost-all-dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109177,
     "status": "ok",
     "timestamp": 1733891973437,
     "user": {
      "displayName": "Liew Cheah Ming",
      "userId": "16761576291408548451"
     },
     "user_tz": -480
    },
    "id": "6UawIgJHObMZ",
    "outputId": "b22c96b3-59ae-4a10-fa5b-53064fd133a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ctcdecode'...\n",
      "remote: Enumerating objects: 1102, done.\u001b[K\n",
      "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
      "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
      "remote: Total 1102 (delta 16), reused 32 (delta 14), pack-reused 1063 (from 1)\u001b[K\n",
      "Receiving objects: 100% (1102/1102), 782.27 KiB | 10.57 MiB/s, done.\n",
      "Resolving deltas: 100% (529/529), done.\n",
      "Submodule 'third_party/ThreadPool' (https://github.com/progschj/ThreadPool.git) registered for path 'third_party/ThreadPool'\n",
      "Submodule 'third_party/kenlm' (https://github.com/kpu/kenlm.git) registered for path 'third_party/kenlm'\n",
      "Cloning into '/content/ctcdecode/third_party/ThreadPool'...\n",
      "remote: Enumerating objects: 82, done.        \n",
      "remote: Counting objects: 100% (26/26), done.        \n",
      "remote: Compressing objects: 100% (9/9), done.        \n",
      "remote: Total 82 (delta 19), reused 17 (delta 17), pack-reused 56 (from 1)        \n",
      "Receiving objects: 100% (82/82), 13.34 KiB | 2.67 MiB/s, done.\n",
      "Resolving deltas: 100% (36/36), done.\n",
      "Cloning into '/content/ctcdecode/third_party/kenlm'...\n",
      "remote: Enumerating objects: 14170, done.        \n",
      "remote: Counting objects: 100% (483/483), done.        \n",
      "remote: Compressing objects: 100% (337/337), done.        \n",
      "remote: Total 14170 (delta 167), reused 410 (delta 132), pack-reused 13687 (from 1)        \n",
      "Receiving objects: 100% (14170/14170), 5.91 MiB | 12.20 MiB/s, done.\n",
      "Resolving deltas: 100% (8047/8047), done.\n",
      "Submodule path 'third_party/ThreadPool': checked out '9a42ec1329f259a5f4881a291db1dcb8f2ad9040'\n",
      "Submodule path 'third_party/kenlm': checked out '35835f1ac4884126458ac89f9bf6dd9ccad561e0'\n",
      "Processing /content/ctcdecode\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: ctcdecode\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Building wheel for ctcdecode (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Failed building wheel for ctcdecode\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for ctcdecode\n",
      "Failed to build ctcdecode\n",
      "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (ctcdecode)\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!rm -rf ctcdecode\n",
    "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
    "!cd ctcdecode && pip install .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 916,
     "status": "ok",
     "timestamp": 1733891974350,
     "user": {
      "displayName": "Liew Cheah Ming",
      "userId": "16761576291408548451"
     },
     "user_tz": -480
    },
    "id": "evfEAy5XzzDF",
    "outputId": "fb220784-73b8-4b51-8411-2e72aff18f9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement ctcdecode-tensorflow (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for ctcdecode-tensorflow\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ctcdecode-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108897,
     "status": "ok",
     "timestamp": 1733892083245,
     "user": {
      "displayName": "Liew Cheah Ming",
      "userId": "16761576291408548451"
     },
     "user_tz": -480
    },
    "id": "2FJZe1T055J6",
    "outputId": "5c42b63a-adcd-4ab5-9c3b-5dcf5605d13e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/parlance/ctcdecode.git@master\n",
      "  Cloning https://github.com/parlance/ctcdecode.git (to revision master) to /tmp/pip-req-build-0ccrsi0_\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/parlance/ctcdecode.git /tmp/pip-req-build-0ccrsi0_\n",
      "  Resolved https://github.com/parlance/ctcdecode.git to commit c90ad94a0b19554f80804fb7812f2a1447a34a70\n",
      "  Running command git submodule update --init --recursive -q\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: ctcdecode\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Building wheel for ctcdecode (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Failed building wheel for ctcdecode\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for ctcdecode\n",
      "Failed to build ctcdecode\n",
      "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (ctcdecode)\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/parlance/ctcdecode.git@master\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8423,
     "status": "ok",
     "timestamp": 1733892091658,
     "user": {
      "displayName": "Liew Cheah Ming",
      "userId": "16761576291408548451"
     },
     "user_tz": -480
    },
    "id": "6Ro4EyYyLAo8",
    "outputId": "e1fc6e96-dc6d-4a5b-834a-319f6e7e6b4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa libsox-fmt-base libsox3 libwavpack1\n",
      "Suggested packages:\n",
      "  libsox-fmt-all\n",
      "The following NEW packages will be installed:\n",
      "  libopencore-amrnb0 libopencore-amrwb0 libsox-fmt-alsa libsox-fmt-base libsox3 libwavpack1 sox\n",
      "0 upgraded, 7 newly installed, 0 to remove and 58 not upgraded.\n",
      "Need to get 617 kB of archives.\n",
      "After this operation, 1,764 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrnb0 amd64 0.1.5-1 [94.8 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libopencore-amrwb0 amd64 0.1.5-1 [49.1 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox3 amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [240 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-alsa amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [11.2 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwavpack1 amd64 5.4.0-1build2 [83.7 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libsox-fmt-base amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [33.7 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 sox amd64 14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1 [104 kB]\n",
      "Fetched 617 kB in 0s (2,712 kB/s)\n",
      "Selecting previously unselected package libopencore-amrnb0:amd64.\n",
      "(Reading database ... 124385 files and directories currently installed.)\n",
      "Preparing to unpack .../0-libopencore-amrnb0_0.1.5-1_amd64.deb ...\n",
      "Unpacking libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
      "Selecting previously unselected package libopencore-amrwb0:amd64.\n",
      "Preparing to unpack .../1-libopencore-amrwb0_0.1.5-1_amd64.deb ...\n",
      "Unpacking libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
      "Selecting previously unselected package libsox3:amd64.\n",
      "Preparing to unpack .../2-libsox3_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
      "Unpacking libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package libsox-fmt-alsa:amd64.\n",
      "Preparing to unpack .../3-libsox-fmt-alsa_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
      "Unpacking libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package libwavpack1:amd64.\n",
      "Preparing to unpack .../4-libwavpack1_5.4.0-1build2_amd64.deb ...\n",
      "Unpacking libwavpack1:amd64 (5.4.0-1build2) ...\n",
      "Selecting previously unselected package libsox-fmt-base:amd64.\n",
      "Preparing to unpack .../5-libsox-fmt-base_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
      "Unpacking libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
      "Selecting previously unselected package sox.\n",
      "Preparing to unpack .../6-sox_14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1_amd64.deb ...\n",
      "Unpacking sox (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
      "Setting up libsox3:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
      "Setting up libopencore-amrwb0:amd64 (0.1.5-1) ...\n",
      "Setting up libsox-fmt-alsa:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
      "Setting up libwavpack1:amd64 (5.4.0-1build2) ...\n",
      "Setting up libopencore-amrnb0:amd64 (0.1.5-1) ...\n",
      "Setting up libsox-fmt-base:amd64 (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
      "Setting up sox (14.4.2+git20190427-2+deb11u2ubuntu0.22.04.1) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y sox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2180,
     "status": "ok",
     "timestamp": 1733892093829,
     "user": {
      "displayName": "Liew Cheah Ming",
      "userId": "16761576291408548451"
     },
     "user_tz": -480
    },
    "id": "YmcFy30Ylg0l"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import scipy.signal\n",
    "import soundfile as sf\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, Sampler, DistributedSampler, DataLoader\n",
    "\n",
    "\n",
    "LABELS = [\n",
    "  \"_\",\n",
    "  \"'\",\n",
    "  \"A\",\n",
    "  \"B\",\n",
    "  \"C\",\n",
    "  \"D\",\n",
    "  \"E\",\n",
    "  \"F\",\n",
    "  \"G\",\n",
    "  \"H\",\n",
    "  \"I\",\n",
    "  \"J\",\n",
    "  \"K\",\n",
    "  \"L\",\n",
    "  \"M\",\n",
    "  \"N\",\n",
    "  \"O\",\n",
    "  \"P\",\n",
    "  \"Q\",\n",
    "  \"R\",\n",
    "  \"S\",\n",
    "  \"T\",\n",
    "  \"U\",\n",
    "  \"V\",\n",
    "  \"W\",\n",
    "  \"X\",\n",
    "  \"Y\",\n",
    "  \"Z\",\n",
    "  \" \"\n",
    "]\n",
    "\n",
    "\n",
    "windows = {\n",
    "    'hamming': lambda N: scipy.signal.get_window('hamming', N),  # Use get_window function\n",
    "    'hann': lambda N: scipy.signal.get_window('hann', N),\n",
    "    'blackman': lambda N: scipy.signal.get_window('blackman', N),\n",
    "    'bartlett': lambda N: scipy.signal.get_window('bartlett', N)\n",
    "}\n",
    "\n",
    "\n",
    "def load_audio(path):\n",
    "    sound, sample_rate = sf.read(path, dtype='int16')\n",
    "    # TODO this should be 32768.0 to get twos-complement range.\n",
    "    # TODO the difference is negligible but should be fixed for new models.\n",
    "    sound = sound.astype('float32') / 32767  # normalize audio\n",
    "    if len(sound.shape) > 1:\n",
    "        if sound.shape[1] == 1:\n",
    "            sound = sound.squeeze()\n",
    "        else:\n",
    "            sound = sound.mean(axis=1)  # multiple channels, average\n",
    "    return sound\n",
    "\n",
    "class SpeechDataset:\n",
    "    def __init__(self, args, df):\n",
    "\n",
    "        self.args = args\n",
    "        self.audio_path = df.audio_path.values.tolist()\n",
    "        self.transcript_path = df.txt_path.values.tolist()\n",
    "        self.labels_map = dict([(LABELS[i], i) for i in range(len(LABELS))])\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        audio_path = self.audio_path[item]\n",
    "        transcript_path = self.transcript_path[item]\n",
    "        try:\n",
    "            spect = self.parse_audio(audio_path)\n",
    "            transcript = self.parse_transcript(transcript_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading item {item}: {audio_path}, {transcript_path}\")\n",
    "            raise e\n",
    "\n",
    "        return spect, transcript\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_path)\n",
    "\n",
    "    def parse_audio(self, audio_path):\n",
    "\n",
    "        y = load_audio(audio_path)\n",
    "\n",
    "        n_fft = int(self.args.sample_rate * self.args.window_size)\n",
    "        win_length = n_fft\n",
    "        hop_length = int(self.args.sample_rate * self.args.window_stride)\n",
    "        # STFT\n",
    "        D = librosa.stft(y, n_fft=n_fft, hop_length=hop_length,\n",
    "                         win_length=win_length, window=self.args.window)\n",
    "        spect, phase = librosa.magphase(D)\n",
    "        # S = log(S+1)\n",
    "        spect = np.log1p(spect)\n",
    "        spect = torch.FloatTensor(spect)\n",
    "        if self.args.normalize:\n",
    "            mean = spect.mean()\n",
    "            std = spect.std()\n",
    "            spect.add_(-mean)\n",
    "            spect.div_(std)\n",
    "\n",
    "        return spect\n",
    "\n",
    "    def parse_transcript(self, transcript_path):\n",
    "        with open(transcript_path, 'r', encoding='utf8') as transcript_file:\n",
    "            transcript = transcript_file.read().replace('\\n', '')\n",
    "        transcript = list(filter(None, [self.labels_map.get(x) for x in list(transcript)]))\n",
    "        return transcript\n",
    "\n",
    "\n",
    "\n",
    "def _collate_fn(batch):\n",
    "    def func(p):\n",
    "        return p[0].size(1)\n",
    "\n",
    "    batch = sorted(batch, key=lambda sample: sample[0].size(1), reverse=True)\n",
    "    longest_sample = max(batch, key=func)[0]\n",
    "    freq_size = longest_sample.size(0)\n",
    "    minibatch_size = len(batch)\n",
    "    max_seqlength = longest_sample.size(1)\n",
    "    inputs = torch.zeros(minibatch_size, 1, freq_size, max_seqlength)\n",
    "    input_percentages = torch.FloatTensor(minibatch_size)\n",
    "    target_sizes = torch.IntTensor(minibatch_size)\n",
    "    targets = []\n",
    "    for x in range(minibatch_size):\n",
    "        sample = batch[0]\n",
    "        tensor = sample[0]\n",
    "        target = sample[1]\n",
    "        seq_length = tensor.size(1)\n",
    "        inputs[x][0].narrow(1, 0, seq_length).copy_(tensor)\n",
    "        input_percentages[x] = seq_length / float(max_seqlength)\n",
    "        target_sizes[x] = len(target)\n",
    "        targets.extend(target)\n",
    "    targets = torch.IntTensor(targets)\n",
    "    return inputs, targets, input_percentages, target_sizes\n",
    "\n",
    "class AudioDataLoader(DataLoader):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Creates a data loader for AudioDatasets.\n",
    "        \"\"\"\n",
    "        super(AudioDataLoader, self).__init__(*args, **kwargs)\n",
    "        self.collate_fn = _collate_fn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1733892093829,
     "user": {
      "displayName": "Liew Cheah Ming",
      "userId": "16761576291408548451"
     },
     "user_tz": -480
    },
    "id": "E_0lvfWOll-j"
   },
   "outputs": [],
   "source": [
    "class args:\n",
    "\n",
    "    # training\n",
    "    seed = 42\n",
    "    epochs = 100\n",
    "    early_stopping_patience = 5  # Decreased patience for early stopping\n",
    "\n",
    "    # data\n",
    "    train_path = r\"/content/drive/MyDrive/datasets/train_manifest.xlsx\"\n",
    "    test_path = r\"/content/drive/MyDrive/datasets/test_manifest.xlsx\"\n",
    "    sample_rate = 16000\n",
    "    batch_size = 32\n",
    "    num_workers = 12\n",
    "    window_size = .002\n",
    "    window_stride = .01\n",
    "    window = \"hamming\"\n",
    "    normalize = True\n",
    "    pin_memory=True\n",
    "\n",
    "    # model\n",
    "    rnn_type = \"lstm\"\n",
    "    hidden_size = 1024\n",
    "    hidden_layers = 5\n",
    "    bidirectional = True\n",
    "    dropout_rate = 0.5 # Added dropout to RNN layers\n",
    "\n",
    "    # optimizer\n",
    "    learning_rate = 0.001\n",
    "    weight_decay = 1e-4\n",
    "    momentum = 0.9\n",
    "    eps = 1e-8\n",
    "    betas = (0.9, 0.999)\n",
    "    max_norm = 100  # Gradient clipping threshold\n",
    "    learning_anneal = 1.05\n",
    "\n",
    "\n",
    "    lr_scheduler = \"ReduceLROnPlateau\"  # Changed to a scheduler that reduces lr based on plateau\n",
    "\n",
    "    # Early Stopping\n",
    "    early_stopping_patience = 5  # Decreased patience for early stopping\n",
    "\n",
    "    # Gradient Accumulation\n",
    "    accumulation_steps = 4  # Used to simulate a larger batch size\n",
    "\n",
    "    # Regularization\n",
    "    max_grad_norm = 1  # Gradient clipping value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1733892093829,
     "user": {
      "displayName": "Liew Cheah Ming",
      "userId": "16761576291408548451"
     },
     "user_tz": -480
    },
    "id": "gDWqAKrDlre3"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "supported_rnns = {\n",
    "    'lstm': nn.LSTM,\n",
    "    'rnn': nn.RNN,\n",
    "    'gru': nn.GRU\n",
    "}\n",
    "supported_rnns_inv = dict((v, k) for k, v in supported_rnns.items())\n",
    "\n",
    "\n",
    "class SequenceWise(nn.Module):\n",
    "    def __init__(self, module):\n",
    "        \"\"\"\n",
    "        Collapses input of dim T*N*H to (T*N)*H, and applies to a module.\n",
    "        Allows handling of variable sequence lengths and minibatch sizes.\n",
    "        :param module: Module to apply input to.\n",
    "        \"\"\"\n",
    "        super(SequenceWise, self).__init__()\n",
    "        self.module = module\n",
    "\n",
    "    def forward(self, x):\n",
    "        t, n = x.size(0), x.size(1)\n",
    "        x = x.view(t * n, -1)\n",
    "        x = self.module(x)\n",
    "        x = x.view(t, n, -1)\n",
    "        return x\n",
    "\n",
    "    def __repr__(self):\n",
    "        tmpstr = self.__class__.__name__ + ' (\\n'\n",
    "        tmpstr += self.module.__repr__()\n",
    "        tmpstr += ')'\n",
    "        return tmpstr\n",
    "\n",
    "\n",
    "class MaskConv(nn.Module):\n",
    "    def __init__(self, seq_module):\n",
    "        \"\"\"\n",
    "        Adds padding to the output of the module based on the given lengths. This is to ensure that the\n",
    "        results of the model do not change when batch sizes change during inference.\n",
    "        Input needs to be in the shape of (BxCxDxT)\n",
    "        :param seq_module: The sequential module containing the conv stack.\n",
    "        \"\"\"\n",
    "        super(MaskConv, self).__init__()\n",
    "        self.seq_module = seq_module\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        \"\"\"\n",
    "        :param x: The input of size BxCxDxT\n",
    "        :param lengths: The actual length of each sequence in the batch\n",
    "        :return: Masked output from the module\n",
    "        \"\"\"\n",
    "        for module in self.seq_module:\n",
    "            x = module(x)\n",
    "            mask = torch.BoolTensor(x.size()).fill_(0)\n",
    "            if x.is_cuda:\n",
    "                mask = mask.cuda()\n",
    "            for i, length in enumerate(lengths):\n",
    "                length = length.item()\n",
    "                if (mask[i].size(2) - length) > 0:\n",
    "                    mask[i].narrow(2, length, mask[i].size(2) - length).fill_(1)\n",
    "            x = x.masked_fill(mask, 0)\n",
    "        return x, lengths\n",
    "\n",
    "\n",
    "class InferenceBatchSoftmax(nn.Module):\n",
    "    def forward(self, input_):\n",
    "        if not self.training:\n",
    "            return F.softmax(input_, dim=-1)\n",
    "        else:\n",
    "            return input_\n",
    "\n",
    "\n",
    "class BatchRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, rnn_type=nn.LSTM, bidirectional=False, batch_norm=True):\n",
    "        super(BatchRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "        self.batch_norm = SequenceWise(nn.BatchNorm1d(input_size)) if batch_norm else None\n",
    "        self.rnn = rnn_type(input_size=input_size, hidden_size=hidden_size,\n",
    "                            bidirectional=bidirectional, bias=True)\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "\n",
    "    def flatten_parameters(self):\n",
    "        self.rnn.flatten_parameters()\n",
    "\n",
    "    def forward(self, x, output_lengths):\n",
    "        if self.batch_norm is not None:\n",
    "            x = self.batch_norm(x)\n",
    "        x = nn.utils.rnn.pack_padded_sequence(x, output_lengths)\n",
    "        x, h = self.rnn(x)\n",
    "        x, _ = nn.utils.rnn.pad_packed_sequence(x)\n",
    "        if self.bidirectional:\n",
    "            x = x.view(x.size(0), x.size(1), 2, -1).sum(2).view(x.size(0), x.size(1), -1)  # (TxNxH*2) -> (TxNxH) by sum\n",
    "        return x\n",
    "\n",
    "\n",
    "class Lookahead(nn.Module):\n",
    "    # Wang et al 2016 - Lookahead Convolution Layer for Unidirectional Recurrent Neural Networks\n",
    "    # input shape - sequence, batch, feature - TxNxH\n",
    "    # output shape - same as input\n",
    "    def __init__(self, n_features, context):\n",
    "        super(Lookahead, self).__init__()\n",
    "        assert context > 0\n",
    "        self.context = context\n",
    "        self.n_features = n_features\n",
    "        self.pad = (0, self.context - 1)\n",
    "        self.conv = nn.Conv1d(self.n_features, self.n_features, kernel_size=self.context, stride=1,\n",
    "                              groups=self.n_features, padding=0, bias=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(0, 1).transpose(1, 2)\n",
    "        x = F.pad(x, pad=self.pad, value=0)\n",
    "        x = self.conv(x)\n",
    "        x = x.transpose(1, 2).transpose(0, 1).contiguous()\n",
    "        return x\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(' \\\n",
    "               + 'n_features=' + str(self.n_features) \\\n",
    "               + ', context=' + str(self.context) + ')'\n",
    "\n",
    "\n",
    "class DeepSpeech(nn.Module):\n",
    "    def __init__(self, rnn_type, labels, rnn_hidden_size, nb_layers, audio_conf,\n",
    "                 bidirectional, context=20):\n",
    "        super(DeepSpeech, self).__init__()\n",
    "\n",
    "        self.hidden_size = rnn_hidden_size\n",
    "        self.hidden_layers = nb_layers\n",
    "        self.rnn_type = rnn_type\n",
    "        self.audio_conf = audio_conf\n",
    "        self.labels = labels\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        sample_rate = self.audio_conf[\"sample_rate\"]\n",
    "        window_size = self.audio_conf[\"window_size\"]\n",
    "        num_classes = len(self.labels)\n",
    "\n",
    "        self.conv = MaskConv(nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(20, 5)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Hardtanh(0, 20, inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=(21, 11), stride=(2, 1), padding=(10, 5)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Hardtanh(0, 20, inplace=True)\n",
    "        ))\n",
    "        # Based on above convolutions and spectrogram size using conv formula (W - F + 2P)/ S+1\n",
    "        rnn_input_size = int(math.floor((sample_rate * window_size) / 2) + 1)\n",
    "        rnn_input_size = int(math.floor(rnn_input_size + 2 * 20 - 41) / 2 + 1)\n",
    "        rnn_input_size = int(math.floor(rnn_input_size + 2 * 10 - 21) / 2 + 1)\n",
    "        rnn_input_size *= 32\n",
    "\n",
    "        rnns = []\n",
    "        rnn = BatchRNN(input_size=rnn_input_size, hidden_size=rnn_hidden_size, rnn_type=rnn_type,\n",
    "                       bidirectional=bidirectional, batch_norm=False)\n",
    "        rnns.append(('0', rnn))\n",
    "        for x in range(nb_layers - 1):\n",
    "            rnn = BatchRNN(input_size=rnn_hidden_size, hidden_size=rnn_hidden_size, rnn_type=rnn_type,\n",
    "                           bidirectional=bidirectional)\n",
    "            rnns.append(('%d' % (x + 1), rnn))\n",
    "        self.rnns = nn.Sequential(OrderedDict(rnns))\n",
    "        self.lookahead = nn.Sequential(\n",
    "            # consider adding batch norm?\n",
    "            Lookahead(rnn_hidden_size, context=context),\n",
    "            nn.Hardtanh(0, 20, inplace=True)\n",
    "        ) if not bidirectional else None\n",
    "\n",
    "        fully_connected = nn.Sequential(\n",
    "            nn.BatchNorm1d(rnn_hidden_size),\n",
    "            nn.Linear(rnn_hidden_size, num_classes, bias=False)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            SequenceWise(fully_connected),\n",
    "        )\n",
    "        self.inference_softmax = InferenceBatchSoftmax()\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        lengths = lengths.cpu().int()\n",
    "        output_lengths = self.get_seq_lens(lengths)\n",
    "        x, _ = self.conv(x, output_lengths)\n",
    "\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # Collapse feature dimension\n",
    "        x = x.transpose(1, 2).transpose(0, 1).contiguous()  # TxNxH\n",
    "\n",
    "        for rnn in self.rnns:\n",
    "            x = rnn(x, output_lengths)\n",
    "\n",
    "        if not self.bidirectional:  # no need for lookahead layer in bidirectional\n",
    "            x = self.lookahead(x)\n",
    "\n",
    "        x = self.fc(x)\n",
    "        x = x.transpose(0, 1)\n",
    "        # identity in training mode, softmax in eval mode\n",
    "        x = self.inference_softmax(x)\n",
    "        return x, output_lengths\n",
    "\n",
    "    def get_seq_lens(self, input_length):\n",
    "        \"\"\"\n",
    "        Given a 1D Tensor or Variable containing integer sequence lengths, return a 1D tensor or variable\n",
    "        containing the size sequences that will be output by the network.\n",
    "        :param input_length: 1D Tensor\n",
    "        :return: 1D Tensor scaled by model\n",
    "        \"\"\"\n",
    "        seq_len = input_length\n",
    "        for m in self.conv.modules():\n",
    "            if type(m) == nn.modules.conv.Conv2d:\n",
    "                seq_len = ((seq_len + 2 * m.padding[1] - m.dilation[1] * (m.kernel_size[1] - 1) - 1) / m.stride[1] + 1)\n",
    "        return seq_len.int()\n",
    "\n",
    "    @classmethod\n",
    "    def load_model(cls, path):\n",
    "        package = torch.load(path, map_location=lambda storage, loc: storage)\n",
    "        model = DeepSpeech.load_model_package(package)\n",
    "        return model\n",
    "\n",
    "    @classmethod\n",
    "    def load_model_package(cls, package):\n",
    "        model = cls(rnn_hidden_size=package['hidden_size'],\n",
    "                    nb_layers=package['hidden_layers'],\n",
    "                    labels=package['labels'],\n",
    "                    audio_conf=package['audio_conf'],\n",
    "                    rnn_type=supported_rnns[package['rnn_type']],\n",
    "                    bidirectional=package.get('bidirectional', True))\n",
    "        model.load_state_dict(package['state_dict'])\n",
    "        return model\n",
    "\n",
    "    def serialize_state(self):\n",
    "        return {\n",
    "            'hidden_size': self.hidden_size,\n",
    "            'hidden_layers': self.hidden_layers,\n",
    "            'rnn_type': supported_rnns_inv.get(self.rnn_type, self.rnn_type.__name__.lower()),\n",
    "            'audio_conf': self.audio_conf,\n",
    "            'labels': self.labels,\n",
    "            'state_dict': self.state_dict(),\n",
    "            'bidirectional': self.bidirectional,\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def get_param_size(model):\n",
    "        params = 0\n",
    "        for p in model.parameters():\n",
    "            tmp = 1\n",
    "            for x in p.size():\n",
    "                tmp *= x\n",
    "            params += tmp\n",
    "        return params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 32934306,
     "status": "error",
     "timestamp": 1733800964944,
     "user": {
      "displayName": "Liew Cheah Ming",
      "userId": "16761576291408548451"
     },
     "user_tz": -480
    },
    "id": "y-qRD7w5lwUM",
    "outputId": "1917d3cf-30bb-4fe3-afc3-9ae28a8920ac"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [34:52<00:00,  3.76s/it]\n",
      "100%|██████████| 336/336 [25:27<00:00,  4.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [1]\tAverage WER 137.660\tAverage CER 83.014\t\n",
      "**** Model Improved !!!! Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:09<00:00,  2.93it/s]\n",
      "100%|██████████| 336/336 [04:56<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [2]\tAverage WER 145.767\tAverage CER 81.608\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:10<00:00,  2.92it/s]\n",
      "100%|██████████| 336/336 [04:54<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [3]\tAverage WER 50.576\tAverage CER 78.953\t\n",
      "**** Model Improved !!!! Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [04:50<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [4]\tAverage WER 30.366\tAverage CER 81.012\t\n",
      "**** Model Improved !!!! Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:12<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [04:35<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [5]\tAverage WER 30.579\tAverage CER 85.693\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [04:21<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [6]\tAverage WER 52.925\tAverage CER 89.073\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [04:14<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [7]\tAverage WER 78.711\tAverage CER 89.347\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [04:14<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [8]\tAverage WER 54.356\tAverage CER 88.836\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [04:02<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [9]\tAverage WER 47.705\tAverage CER 89.166\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:56<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [10]\tAverage WER 64.831\tAverage CER 92.206\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:51<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [11]\tAverage WER 76.366\tAverage CER 94.128\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:49<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [12]\tAverage WER 128.690\tAverage CER 96.511\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:44<00:00,  1.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [13]\tAverage WER 180.569\tAverage CER 97.465\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:38<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [14]\tAverage WER 258.373\tAverage CER 98.121\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:31<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [15]\tAverage WER 349.652\tAverage CER 98.522\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:32<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [16]\tAverage WER 288.469\tAverage CER 97.907\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:26<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [17]\tAverage WER 301.258\tAverage CER 97.881\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:25<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [18]\tAverage WER 202.314\tAverage CER 96.865\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:16<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [19]\tAverage WER 538.166\tAverage CER 99.937\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:17<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [20]\tAverage WER 522.500\tAverage CER 99.764\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:12<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:17<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [21]\tAverage WER 536.845\tAverage CER 99.903\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:19<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [22]\tAverage WER 458.818\tAverage CER 99.439\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:12<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:21<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [23]\tAverage WER 108.548\tAverage CER 94.070\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:23<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [24]\tAverage WER 49.113\tAverage CER 89.782\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:12<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:26<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [25]\tAverage WER 28.574\tAverage CER 86.185\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:28<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [26]\tAverage WER 16.093\tAverage CER 83.971\t\n",
      "**** Model Improved !!!! Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:29<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [27]\tAverage WER 13.076\tAverage CER 84.028\t\n",
      "**** Model Improved !!!! Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:12<00:00,  2.89it/s]\n",
      "100%|██████████| 336/336 [03:29<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [28]\tAverage WER 13.777\tAverage CER 83.848\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:32<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [29]\tAverage WER 9.410\tAverage CER 82.342\t\n",
      "**** Model Improved !!!! Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:12<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:29<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [30]\tAverage WER 11.163\tAverage CER 82.898\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:28<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [31]\tAverage WER 10.962\tAverage CER 82.503\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:29<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [32]\tAverage WER 13.042\tAverage CER 83.927\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:30<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [33]\tAverage WER 9.848\tAverage CER 82.193\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:48<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [34]\tAverage WER 13.204\tAverage CER 79.805\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:31<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [35]\tAverage WER 9.405\tAverage CER 89.063\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:30<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [36]\tAverage WER 10.176\tAverage CER 87.170\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:29<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [37]\tAverage WER 11.734\tAverage CER 90.409\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:40<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [38]\tAverage WER 68.559\tAverage CER 93.065\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:39<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [39]\tAverage WER 17.750\tAverage CER 79.539\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:40<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [40]\tAverage WER 16.292\tAverage CER 81.069\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:41<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [41]\tAverage WER 16.726\tAverage CER 81.569\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:40<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [42]\tAverage WER 16.864\tAverage CER 80.647\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:41<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [43]\tAverage WER 14.327\tAverage CER 78.853\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:42<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [44]\tAverage WER 13.447\tAverage CER 78.191\t\n",
      "**** Model Improved !!!! Saving Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:12<00:00,  2.89it/s]\n",
      "100%|██████████| 336/336 [03:39<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [45]\tAverage WER 14.073\tAverage CER 81.008\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:42<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [46]\tAverage WER 13.192\tAverage CER 81.138\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:40<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [47]\tAverage WER 14.670\tAverage CER 83.862\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:41<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [48]\tAverage WER 15.849\tAverage CER 81.394\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:40<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [49]\tAverage WER 13.852\tAverage CER 82.591\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:40<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [50]\tAverage WER 14.655\tAverage CER 81.049\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:40<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [51]\tAverage WER 15.104\tAverage CER 79.004\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:39<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [52]\tAverage WER 12.970\tAverage CER 80.820\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:39<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [53]\tAverage WER 12.851\tAverage CER 84.479\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:41<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [54]\tAverage WER 15.792\tAverage CER 82.502\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:38<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [55]\tAverage WER 16.599\tAverage CER 80.916\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:39<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [56]\tAverage WER 15.509\tAverage CER 82.511\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:47<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [57]\tAverage WER 17.061\tAverage CER 80.769\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:27<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [58]\tAverage WER 24.650\tAverage CER 86.823\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:30<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [59]\tAverage WER 44.962\tAverage CER 80.881\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:34<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [60]\tAverage WER 24.138\tAverage CER 81.280\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [05:04<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [61]\tAverage WER 510.460\tAverage CER 93.734\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:20<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [62]\tAverage WER 261.933\tAverage CER 92.121\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:22<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [63]\tAverage WER 233.796\tAverage CER 92.586\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:23<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [64]\tAverage WER 222.607\tAverage CER 94.277\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:25<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [65]\tAverage WER 179.023\tAverage CER 88.065\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:27<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [66]\tAverage WER 105.740\tAverage CER 87.659\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:23<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [67]\tAverage WER 139.171\tAverage CER 90.745\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:24<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [68]\tAverage WER 223.674\tAverage CER 90.724\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:30<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [69]\tAverage WER 34.202\tAverage CER 82.101\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:36<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [70]\tAverage WER 40.899\tAverage CER 78.418\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:32<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [71]\tAverage WER 82.394\tAverage CER 87.007\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:26<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [72]\tAverage WER 257.998\tAverage CER 92.366\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.90it/s]\n",
      "100%|██████████| 336/336 [03:28<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [73]\tAverage WER 226.408\tAverage CER 87.679\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:31<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [74]\tAverage WER 235.464\tAverage CER 90.718\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:25<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [75]\tAverage WER 277.493\tAverage CER 89.713\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [03:11<00:00,  2.91it/s]\n",
      "100%|██████████| 336/336 [03:26<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Summary Epoch: [76]\tAverage WER 238.720\tAverage CER 88.147\t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 409/557 [02:10<00:47,  3.13it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-aa3edbb5705f>\u001b[0m in \u001b[0;36m<cell line: 209>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mArgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nvidia-smi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-aa3edbb5705f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         wer, cer, output_data = test_fn(args=args,\n\u001b[1;32m    195\u001b[0m                                         \u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-aa3edbb5705f>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(args, train_loader, model, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mcurrent_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.nn import CTCLoss\n",
    "from tqdm import tqdm  # for progress bar\n",
    "import pandas as pd  # for reading CSV files\n",
    "# Ensure you import your custom modules as well\n",
    "\n",
    "\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.nn import CTCLoss\n",
    "\n",
    "\n",
    "class AverageMeter:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def train_fn(args, train_loader, model, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    t = tqdm(train_loader)\n",
    "    for i, data in enumerate(t):\n",
    "\n",
    "        inputs, targets, input_percentages, target_sizes = data\n",
    "        input_sizes = input_percentages.mul_(int(inputs.size(3))).int()\n",
    "\n",
    "        inputs = inputs.to(args.device)\n",
    "        target = targets.to(args.device)\n",
    "        target_sizes = target_sizes.to(args.device)\n",
    "\n",
    "        out, output_sizes = model(inputs, input_sizes)\n",
    "        out = out.transpose(0, 1) # TxNxH\n",
    "\n",
    "\n",
    "        float_out = out.float() # ensure float32 for loss\n",
    "\n",
    "        output_sizes = output_sizes.to(args.device)\n",
    "        loss = criterion(float_out, targets, output_sizes, target_sizes).to(args.device)\n",
    "        loss = loss / inputs.size(0) # average the loss by minibatch\n",
    "        loss_value = loss.item()\n",
    "        loss_value = loss.item()\n",
    "\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "\n",
    "        losses.update(loss_value, inputs.size(0))\n",
    "\n",
    "    return losses.avg\n",
    "\n",
    "\n",
    "def test_fn(args, test_loader, model, decoder, target_decoder):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_cer, total_wer, num_tokens, num_chars = 0, 0, 0, 0\n",
    "    output_data = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        t = tqdm(test_loader)\n",
    "        for i, data in enumerate(t):\n",
    "\n",
    "            inputs, targets, input_percentages, target_sizes = data\n",
    "            input_sizes = input_percentages.mul_(int(inputs.size(3))).int()\n",
    "            inputs = inputs.to(args.device)\n",
    "\n",
    "\n",
    "            inputs = inputs.to(args.device)\n",
    "            targets = targets.to(args.device)\n",
    "            target_sizes = target_sizes.to(args.device)\n",
    "\n",
    "            # unflatten targets\n",
    "            split_targets = []\n",
    "            offset = 0\n",
    "            for size in target_sizes:\n",
    "                split_targets.append(targets[offset:offset + size])\n",
    "                offset += size\n",
    "\n",
    "            out, output_sizes = model(inputs, input_sizes)\n",
    "\n",
    "            decoded_output, _ = decoder.decode(out, output_sizes)\n",
    "            target_strings = target_decoder.convert_to_strings(split_targets)\n",
    "\n",
    "            # add output to data array, and continue\n",
    "            output_data.append((out.cpu(), output_sizes, target_strings))\n",
    "\n",
    "            for x in range(len(target_strings)):\n",
    "                transcript, reference = decoded_output[x][0], target_strings[x][0]\n",
    "\n",
    "                wer_inst = decoder.wer(transcript, reference)\n",
    "                cer_inst = decoder.cer(transcript, reference)\n",
    "                total_wer += wer_inst\n",
    "                total_cer += cer_inst\n",
    "                num_tokens += len(reference.split())\n",
    "                num_chars += len(reference.replace(' ',''))\n",
    "\n",
    "        wer = float(total_wer) / num_tokens\n",
    "        cer = float(total_cer) / num_chars\n",
    "        return wer * 100, cer * 100, output_data\n",
    "\n",
    "\n",
    "def main(args):\n",
    "\n",
    "\n",
    "    # Set seeds for determinism\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    random.seed(args.seed)\n",
    "\n",
    "    args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device:\", args.device)\n",
    "\n",
    "\n",
    "\n",
    "    labels = LABELS\n",
    "\n",
    "    audio_conf = dict(sample_rate=args.sample_rate,\n",
    "                      window_size=args.window_size,\n",
    "                      window_stride=args.window_stride,\n",
    "                      window=args.window)\n",
    "\n",
    "    rnn_type = args.rnn_type.lower()\n",
    "    assert rnn_type in supported_rnns, \"rnn_type should be either lstm, rnn or gru\"\n",
    "    model = DeepSpeech(rnn_hidden_size=args.hidden_size,\n",
    "                       nb_layers=args.hidden_layers,\n",
    "                       labels=labels,\n",
    "                       rnn_type=supported_rnns[rnn_type],\n",
    "                       audio_conf=audio_conf,\n",
    "                       bidirectional=args.bidirectional)\n",
    "\n",
    "\n",
    "    # Data setup\n",
    "    evaluation_decoder = GreedyDecoder(model.labels) # Decoder used for validation\n",
    "\n",
    "    train_df = pd.read_csv(args.train_path, names=['audio_path', 'txt_path'])\n",
    "    train_dataset = SpeechDataset(args=args, df=train_df)\n",
    "\n",
    "    test_df = pd.read_csv(args.test_path, names=['audio_path', 'txt_path'])\n",
    "    test_dataset = SpeechDataset(args=args, df=test_df)\n",
    "\n",
    "\n",
    "\n",
    "    train_loader = AudioDataLoader(dataset=train_dataset,\n",
    "                                   num_workers=args.num_workers,\n",
    "                                   batch_size=args.batch_size)\n",
    "\n",
    "    test_loader = AudioDataLoader(dataset=test_dataset,\n",
    "                                  num_workers=args.num_workers,\n",
    "                                  batch_size=args.batch_size)\n",
    "\n",
    "    model = model.to(args.device)\n",
    "    parameters = model.parameters()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(parameters,\n",
    "                                  lr=args.learning_rate,\n",
    "                                  betas=args.betas,\n",
    "                                  eps=args.eps,\n",
    "                                  weight_decay=args.weight_decay)\n",
    "\n",
    "    criterion = CTCLoss()\n",
    "\n",
    "    best_score = 99999\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        train_loss = train_fn(args, train_loader, model, optimizer, criterion, epoch)\n",
    "        wer, cer, output_data = test_fn(args=args,\n",
    "                                        test_loader=test_loader,\n",
    "                                        model=model,\n",
    "                                        decoder=evaluation_decoder,\n",
    "                                        target_decoder=evaluation_decoder)\n",
    "\n",
    "        print('Validation Summary Epoch: [{0}]\\t'\n",
    "              'Average WER {wer:.3f}\\t'\n",
    "              'Average CER {cer:.3f}\\t'.format(epoch + 1, wer=wer, cer=cer))\n",
    "\n",
    "        if (wer+cer)/2 < best_score:\n",
    "            print(\"**** Model Improved !!!! Saving Model\")\n",
    "            torch.save(model.state_dict(), f\"best_model.bin\")\n",
    "            best_score = (wer+cer)/2\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Args = args()\n",
    "    main(args=args)\n",
    "\n",
    "!nvidia-smi\n",
    "\n",
    "if os.path.exists(\"best_model.bin\"):\n",
    "    model.load_state_dict(torch.load(\"best_model.bin\"))\n",
    "    print(\"Loaded the saved model.\")\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "torch.save(model.state_dict(), \"/content/drive/MyDrive/advanced machine learning/best_model.bin\")\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "for data in train_loader:\n",
    "    optimizer.zero_grad()\n",
    "    with torch.cuda.amp.autocast():\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "\n",
    "with torch.profiler.profile(\n",
    "    activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler('./log'),\n",
    "    record_shapes=True\n",
    ") as prof:\n",
    "    train_fn(...)\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\"))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 502,
     "status": "ok",
     "timestamp": 1733766220314,
     "user": {
      "displayName": "Liew Cheah Ming",
      "userId": "16761576291408548451"
     },
     "user_tz": -480
    },
    "id": "54wEeuLJhPdi",
    "outputId": "267acc62-c4f0-4751-8506-794a86d7a132"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores available: 12\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Number of CPU cores available:\", os.cpu_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10528,
     "status": "ok",
     "timestamp": 1733892105582,
     "user": {
      "displayName": "Liew Cheah Ming",
      "userId": "16761576291408548451"
     },
     "user_tz": -480
    },
    "id": "doj187jBAuba",
    "outputId": "42367a5b-bfdf-40c2-8410-7f2c71452b9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-5.8.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.5.1 (from gradio)\n",
      "  Downloading gradio_client-1.5.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.3)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
      "Collecting markupsafe~=2.0 (from gradio)\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.3)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.19-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading ruff-0.8.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio) (2024.10.0)\n",
      "Collecting websockets<15.0,>=10.0 (from gradio-client==1.5.1->gradio)\n",
      "  Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.27.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Downloading gradio-5.8.0-py3-none-any.whl (57.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.2/57.2 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.5.1-py3-none-any.whl (320 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.2/320.2 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Downloading python_multipart-0.0.19-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.8.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m112.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
      "  Attempting uninstall: markupsafe\n",
      "    Found existing installation: MarkupSafe 3.0.2\n",
      "    Uninstalling MarkupSafe-3.0.2:\n",
      "      Successfully uninstalled MarkupSafe-3.0.2\n",
      "Successfully installed aiofiles-23.2.1 fastapi-0.115.6 ffmpy-0.4.0 gradio-5.8.0 gradio-client-1.5.1 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.19 ruff-0.8.2 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.13.2 uvicorn-0.32.1 websockets-14.1\n"
     ]
    }
   ],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2970,
     "status": "error",
     "timestamp": 1733892360948,
     "user": {
      "displayName": "Liew Cheah Ming",
      "userId": "16761576291408548451"
     },
     "user_tz": -480
    },
    "id": "A4t1peW1pprJ",
    "outputId": "a994474a-548a-4580-a8c8-3c3c06b76e7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (5.8.0)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.6)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
      "Requirement already satisfied: gradio-client==1.5.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.1)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.28.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.3)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.3)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.19)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.8.2)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.41.3)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.15.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.32.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio) (2024.10.0)\n",
      "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.1->gradio) (14.1)\n",
      "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (3.16.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (3.4.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->torchaudio) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.27.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-780b3adf11db>:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  package = torch.load(model_path, map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "KeyError: 'hidden_size'. Please verify the structure of your checkpoint.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-780b3adf11db>\u001b[0m in \u001b[0;36mload_model_package\u001b[0;34m(cls, package)\u001b[0m\n\u001b[1;32m     15\u001b[0m             model = cls(\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpackage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hidden_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Key might need verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0mhidden_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpackage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hidden_layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'hidden_size'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-780b3adf11db>\u001b[0m in \u001b[0;36m<cell line: 88>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;31m# Load the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/advanced-machine-learning/best_model.bin\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_deepspeech_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;31m# Create the Gradio interface\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-780b3adf11db>\u001b[0m in \u001b[0;36mload_deepspeech_model\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_deepspeech_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mpackage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepSpeech\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0maudio_conf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'audio_conf'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-780b3adf11db>\u001b[0m in \u001b[0;36mload_model_package\u001b[0;34m(cls, package)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"KeyError: {e}. Please verify the structure of your checkpoint.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: KeyError: 'hidden_size'. Please verify the structure of your checkpoint."
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "!pip install gradio torchaudio\n",
    "\n",
    "import gradio as gr\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio.transforms import MelSpectrogram, Resample\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DeepSpeech(torch.nn.Module):\n",
    "    @classmethod\n",
    "    def load_model_package(cls, package):\n",
    "        try:\n",
    "            model = cls(\n",
    "                hidden_size=package['hidden_size'],  # Key might need verification\n",
    "                hidden_layers=package['hidden_layers'],\n",
    "                labels=package['labels'],\n",
    "                audio_conf=package['audio_conf'],\n",
    "                rnn_type=supported_rnns[package['rnn_type']],\n",
    "                bidirectional=package.get('bidirectional', True)\n",
    "            )\n",
    "            model.load_state_dict(package['state_dict'])\n",
    "            return model\n",
    "        except KeyError as e:\n",
    "            raise ValueError(f\"KeyError: {e}. Please verify the structure of your checkpoint.\")\n",
    "\n",
    "\n",
    "# Function to load the model\n",
    "def load_deepspeech_model(model_path):\n",
    "    package = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    model = DeepSpeech.load_model_package(package)\n",
    "    labels = package['labels']\n",
    "    audio_conf = package['audio_conf']\n",
    "    return model, labels, audio_conf\n",
    "\n",
    "\n",
    "# Function for preprocessing and inference\n",
    "def transcribe(audio, model, labels, audio_conf):\n",
    "    try:\n",
    "        # Load the waveform and sample rate\n",
    "        waveform, sample_rate = torchaudio.load(audio.name)\n",
    "\n",
    "        # Resample if necessary\n",
    "        target_sample_rate = audio_conf[\"sample_rate\"]\n",
    "        if sample_rate != target_sample_rate:\n",
    "            resampler = Resample(orig_freq=sample_rate, new_freq=target_sample_rate)\n",
    "            waveform = resampler(waveform)\n",
    "\n",
    "        # Convert to MelSpectrogram\n",
    "        mel_spectrogram = MelSpectrogram(\n",
    "            sample_rate=target_sample_rate,\n",
    "            n_fft=int(target_sample_rate * audio_conf[\"window_size\"]),\n",
    "            win_length=int(target_sample_rate * audio_conf[\"window_size\"]),\n",
    "            hop_length=int(target_sample_rate * audio_conf[\"window_stride\"]),\n",
    "            n_mels=80\n",
    "        )\n",
    "        spectrogram = mel_spectrogram(waveform)\n",
    "        spectrogram = torch.log1p(spectrogram)\n",
    "\n",
    "        # Normalize\n",
    "        spectrogram -= spectrogram.mean()\n",
    "        spectrogram /= spectrogram.std()\n",
    "\n",
    "        # Add batch and channel dimensions\n",
    "        spectrogram = spectrogram.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        # Lengths for RNN\n",
    "        lengths = torch.tensor([spectrogram.size(3)], dtype=torch.int32)\n",
    "\n",
    "        # Run inference\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output, _ = model(spectrogram, lengths)\n",
    "            output = output[0].cpu().numpy()\n",
    "            output = np.argmax(output, axis=-1)\n",
    "\n",
    "        # Decode the transcription\n",
    "        transcription = \"\".join([labels[i] for i in output if i != len(labels) - 1])\n",
    "        return transcription\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error during transcription: {str(e)}\"\n",
    "\n",
    "\n",
    "# Load the model\n",
    "model_path = \"/content/drive/MyDrive/advanced-machine-learning/best_model.bin\"\n",
    "model, labels, audio_conf = load_deepspeech_model(model_path)\n",
    "\n",
    "# Create the Gradio interface\n",
    "def gradio_transcribe(audio):\n",
    "    return transcribe(audio, model, labels, audio_conf)\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=gradio_transcribe,\n",
    "    inputs=gr.Audio(source=\"upload\", type=\"file\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Speech Recognition\",\n",
    "    description=\"Upload an audio file and get its transcription.\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "interface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN/KgFliv6tldLIZXGC3YqV",
   "gpuType": "T4",
   "machine_shape": "hm",
   "mount_file_id": "1PdGWHGwwMvgWLeuoLslsXdqjEe0QPix2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
