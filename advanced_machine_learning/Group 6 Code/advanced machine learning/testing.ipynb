{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4055,
     "status": "ok",
     "timestamp": 1734005880528,
     "user": {
      "displayName": "Liew Cheah Ming",
      "userId": "16761576291408548451"
     },
     "user_tz": -480
    },
    "id": "GAxpgFrztpeS",
    "outputId": "83a43551-979a-4ff4-b4a8-e779cb97c2c8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-69-686f47a8c518>:320: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location='cpu')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribed Text: TN TOEES\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "\n",
    "####################################################\n",
    "# Configuration and Label Setup (Adjust as needed)\n",
    "####################################################\n",
    "audio_conf = {\n",
    "    'sample_rate': 16000,      # Match your training sample_rate\n",
    "    'window_size': 0.002,       # Match your training window_size\n",
    "    'window_stride': 0.01,     # Match your training window_stride\n",
    "    'window': 'hamming',       # Match your training window type\n",
    "}\n",
    "\n",
    "hidden_size = 1024      # Match rnn_hidden_size from training\n",
    "hidden_layers = 5        # Match nb_layers from training\n",
    "rnn_type = 'lstm'        # 'lstm', 'gru', or 'rnn' used during training\n",
    "bidirectional = True      # Match your training setup\n",
    "\n",
    "LABELS = [\n",
    "    \"_\", \"'\",\n",
    "    \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\",\n",
    "    \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\",\n",
    "    \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\",\n",
    "    \"V\", \"W\", \"X\", \"Y\", \"Z\", \" \"\n",
    "]\n",
    "\n",
    "supported_rnns = {\n",
    "    'lstm': nn.LSTM,\n",
    "    'rnn': nn.RNN,\n",
    "    'gru': nn.GRU\n",
    "}\n",
    "supported_rnns_inv = dict((v, k) for k, v in supported_rnns.items())\n",
    "\n",
    "####################################################\n",
    "# Utility Classes\n",
    "####################################################\n",
    "class SequenceWise(nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super(SequenceWise, self).__init__()\n",
    "        self.module = module\n",
    "\n",
    "    def forward(self, x):\n",
    "        t, n = x.size(0), x.size(1)\n",
    "        x = x.view(t * n, -1)\n",
    "        x = self.module(x)\n",
    "        x = x.view(t, n, -1)\n",
    "        return x\n",
    "\n",
    "class MaskConv(nn.Module):\n",
    "    def __init__(self, seq_module):\n",
    "        super(MaskConv, self).__init__()\n",
    "        self.seq_module = seq_module\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        for module in self.seq_module:\n",
    "            x = module(x)\n",
    "            mask = torch.BoolTensor(x.size()).fill_(0)\n",
    "            if x.is_cuda:\n",
    "                mask = mask.cuda()\n",
    "            for i, length in enumerate(lengths):\n",
    "                length = length.item()\n",
    "                if (mask[i].size(2) - length) > 0:\n",
    "                    mask[i].narrow(2, length, mask[i].size(2) - length).fill_(1)\n",
    "            x = x.masked_fill(mask, 0)\n",
    "        return x, lengths\n",
    "\n",
    "class InferenceBatchSoftmax(nn.Module):\n",
    "    def forward(self, input_):\n",
    "        if not self.training:\n",
    "            return F.softmax(input_, dim=-1)\n",
    "        else:\n",
    "            return input_\n",
    "\n",
    "class BatchRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, rnn_type=nn.LSTM, bidirectional=False, batch_norm=True):\n",
    "        super(BatchRNN, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "        self.batch_norm = SequenceWise(nn.BatchNorm1d(input_size)) if batch_norm else None\n",
    "        self.rnn = rnn_type(input_size=input_size, hidden_size=hidden_size,\n",
    "                            bidirectional=bidirectional, bias=True)\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "\n",
    "    def flatten_parameters(self):\n",
    "        self.rnn.flatten_parameters()\n",
    "\n",
    "    def forward(self, x, output_lengths):\n",
    "        if self.batch_norm is not None:\n",
    "            x = self.batch_norm(x)\n",
    "        x = nn.utils.rnn.pack_padded_sequence(x, output_lengths)\n",
    "        x, _ = self.rnn(x)\n",
    "        x, _ = nn.utils.rnn.pad_packed_sequence(x)\n",
    "        if self.bidirectional:\n",
    "            # (TxNxH*2) -> (TxNxH) by sum of directions\n",
    "            x = x.view(x.size(0), x.size(1), 2, -1).sum(2).view(x.size(0), x.size(1), -1)\n",
    "        return x\n",
    "\n",
    "class Lookahead(nn.Module):\n",
    "    # Wang et al 2016 - Lookahead Convolution Layer for Unidirectional RNN\n",
    "    def __init__(self, n_features, context):\n",
    "        super(Lookahead, self).__init__()\n",
    "        assert context > 0\n",
    "        self.context = context\n",
    "        self.n_features = n_features\n",
    "        self.pad = (0, self.context - 1)\n",
    "        self.conv = nn.Conv1d(self.n_features, self.n_features, kernel_size=self.context,\n",
    "                              stride=1, groups=self.n_features, padding=0, bias=None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.transpose(0, 1).transpose(1, 2)  # N, H, T\n",
    "        x = F.pad(x, pad=self.pad, value=0)\n",
    "        x = self.conv(x)\n",
    "        x = x.transpose(1, 2).transpose(0, 1).contiguous()\n",
    "        return x\n",
    "\n",
    "####################################################\n",
    "# Decoder Base Class and GreedyDecoder\n",
    "####################################################\n",
    "class Decoder(object):\n",
    "    def __init__(self, labels, blank_index=0):\n",
    "        self.labels = labels\n",
    "        self.int_to_char = dict([(i, c) for (i, c) in enumerate(labels)])\n",
    "        self.blank_index = blank_index\n",
    "        space_index = len(labels)\n",
    "        if ' ' in labels:\n",
    "            space_index = labels.index(' ')\n",
    "        self.space_index = space_index\n",
    "\n",
    "    def wer(self, s1, s2):\n",
    "        # Simple WER calculation (not needed for this inference script, but left for completeness)\n",
    "        import Levenshtein as Lev\n",
    "        words1 = s1.split()\n",
    "        words2 = s2.split()\n",
    "        return Lev.distance(' '.join(words1), ' '.join(words2)) / float(len(words1) or 1)\n",
    "\n",
    "    def cer(self, s1, s2):\n",
    "        import Levenshtein as Lev\n",
    "        s1, s2 = s1.replace(' ', ''), s2.replace(' ', '')\n",
    "        if len(s1) == 0 and len(s2) == 0:\n",
    "            return 0.0\n",
    "        return Lev.distance(s1, s2)\n",
    "\n",
    "    def decode(self, probs, sizes=None):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class GreedyDecoder(Decoder):\n",
    "    def __init__(self, labels, blank_index=0):\n",
    "        super(GreedyDecoder, self).__init__(labels, blank_index)\n",
    "\n",
    "    def convert_to_strings(self, sequences, sizes=None, remove_repetitions=False, return_offsets=False):\n",
    "        strings = []\n",
    "        offsets = [] if return_offsets else None\n",
    "        for x in range(len(sequences)):\n",
    "            seq_len = sizes[x] if sizes is not None else len(sequences[x])\n",
    "            string, string_offsets = self.process_string(sequences[x], seq_len, remove_repetitions)\n",
    "            strings.append([string])  # one path\n",
    "            if return_offsets:\n",
    "                offsets.append([string_offsets])\n",
    "        if return_offsets:\n",
    "            return strings, offsets\n",
    "        else:\n",
    "            return strings\n",
    "\n",
    "    def process_string(self, sequence, size, remove_repetitions=False):\n",
    "        string = ''\n",
    "        offsets = []\n",
    "        for i in range(size):\n",
    "            char = self.int_to_char[sequence[i].item()]\n",
    "            if char != self.int_to_char[self.blank_index]:\n",
    "                if remove_repetitions and i != 0 and char == self.int_to_char[sequence[i - 1].item()]:\n",
    "                    pass\n",
    "                elif char == self.labels[self.space_index]:\n",
    "                    string += ' '\n",
    "                    offsets.append(i)\n",
    "                else:\n",
    "                    string = string + char\n",
    "                    offsets.append(i)\n",
    "        return string, torch.tensor(offsets, dtype=torch.int)\n",
    "\n",
    "    def decode(self, probs, sizes=None):\n",
    "        _, max_probs = torch.max(probs, 2)\n",
    "        strings, offsets = self.convert_to_strings(\n",
    "            max_probs.view(max_probs.size(0), max_probs.size(1)),\n",
    "            sizes,\n",
    "            remove_repetitions=True,\n",
    "            return_offsets=True\n",
    "        )\n",
    "        return strings, offsets\n",
    "\n",
    "\n",
    "####################################################\n",
    "# DeepSpeech Model Class\n",
    "####################################################\n",
    "class DeepSpeech(nn.Module):\n",
    "    def __init__(self, rnn_type, labels, rnn_hidden_size, nb_layers, audio_conf, bidirectional, context=20):\n",
    "        super(DeepSpeech, self).__init__()\n",
    "        self.hidden_size = rnn_hidden_size\n",
    "        self.hidden_layers = nb_layers\n",
    "        self.rnn_type = rnn_type\n",
    "        self.audio_conf = audio_conf\n",
    "        self.labels = labels\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        sample_rate = self.audio_conf[\"sample_rate\"]\n",
    "        window_size = self.audio_conf[\"window_size\"]\n",
    "        num_classes = len(self.labels)\n",
    "\n",
    "        self.conv = MaskConv(nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=(41, 11), stride=(2, 2), padding=(20, 5)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Hardtanh(0, 20, inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=(21, 11), stride=(2, 1), padding=(10, 5)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Hardtanh(0, 20, inplace=True)\n",
    "        ))\n",
    "\n",
    "        # Calculate RNN input size\n",
    "        rnn_input_size = int(math.floor((sample_rate * window_size) / 2) + 1)\n",
    "        rnn_input_size = int(math.floor(rnn_input_size + 2 * 20 - 41) / 2 + 1)\n",
    "        rnn_input_size = int(math.floor(rnn_input_size + 2 * 10 - 21) / 2 + 1)\n",
    "        rnn_input_size *= 32\n",
    "\n",
    "        rnns = []\n",
    "        rnn = BatchRNN(input_size=rnn_input_size, hidden_size=rnn_hidden_size,\n",
    "                       rnn_type=rnn_type, bidirectional=bidirectional, batch_norm=False)\n",
    "        rnns.append(('0', rnn))\n",
    "        for x in range(nb_layers - 1):\n",
    "            rnn = BatchRNN(input_size=rnn_hidden_size, hidden_size=rnn_hidden_size,\n",
    "                           rnn_type=rnn_type, bidirectional=bidirectional)\n",
    "            rnns.append(('%d' % (x + 1), rnn))\n",
    "        self.rnns = nn.Sequential(OrderedDict(rnns))\n",
    "\n",
    "        self.lookahead = nn.Sequential(\n",
    "            Lookahead(rnn_hidden_size, context=context),\n",
    "            nn.Hardtanh(0, 20, inplace=True)\n",
    "        ) if not bidirectional else None\n",
    "\n",
    "        fully_connected = nn.Sequential(\n",
    "            nn.BatchNorm1d(rnn_hidden_size),\n",
    "            nn.Linear(rnn_hidden_size, num_classes, bias=False)\n",
    "        )\n",
    "        self.fc = nn.Sequential(SequenceWise(fully_connected))\n",
    "\n",
    "        self.inference_softmax = InferenceBatchSoftmax()\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        lengths = lengths.cpu().int()\n",
    "        output_lengths = self.get_seq_lens(lengths)\n",
    "        x, _ = self.conv(x, output_lengths)\n",
    "\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # collapse feature dim\n",
    "        x = x.transpose(1, 2).transpose(0, 1).contiguous()   # TxNxH\n",
    "\n",
    "        for rnn in self.rnns:\n",
    "            x = rnn(x, output_lengths)\n",
    "\n",
    "        if not self.bidirectional:\n",
    "            x = self.lookahead(x)\n",
    "\n",
    "        x = self.fc(x)\n",
    "        x = x.transpose(0, 1)\n",
    "        x = self.inference_softmax(x)\n",
    "        return x, output_lengths\n",
    "\n",
    "    def get_seq_lens(self, input_length):\n",
    "        seq_len = input_length\n",
    "        for m in self.conv.modules():\n",
    "            if type(m) == nn.Conv2d:\n",
    "                seq_len = ((seq_len + 2 * m.padding[1] - m.dilation[1] * (m.kernel_size[1] - 1) - 1) / m.stride[1] + 1)\n",
    "        return seq_len.int()\n",
    "\n",
    "####################################################\n",
    "# Audio Loading and Preprocessing\n",
    "####################################################\n",
    "def load_audio(audio_path, sample_rate):\n",
    "    y, sr = librosa.load(audio_path, sr=sample_rate)\n",
    "    n_fft = int(sample_rate * audio_conf['window_size'])\n",
    "    hop_length = int(sample_rate * audio_conf['window_stride'])\n",
    "    win_length = n_fft\n",
    "\n",
    "    D = librosa.stft(y, n_fft=n_fft, hop_length=hop_length, win_length=win_length, window=audio_conf['window'])\n",
    "    spect, _ = librosa.magphase(D)\n",
    "    spect = np.log1p(spect)  # log(1 + spect)\n",
    "\n",
    "    mean = spect.mean()\n",
    "    std = spect.std()\n",
    "    spect = (spect - mean) / std\n",
    "\n",
    "    spect = torch.FloatTensor(spect)\n",
    "    return spect\n",
    "\n",
    "def prepare_input_tensor(spect):\n",
    "    spect = spect.unsqueeze(0).unsqueeze(0)  # [1, 1, freq, time]\n",
    "    return spect\n",
    "\n",
    "####################################################\n",
    "# Main Inference Logic\n",
    "####################################################\n",
    "\n",
    "# Instantiate the model\n",
    "model = DeepSpeech(\n",
    "    rnn_type=supported_rnns[rnn_type],\n",
    "    labels=LABELS,\n",
    "    rnn_hidden_size=hidden_size,\n",
    "    nb_layers=hidden_layers,\n",
    "    audio_conf=audio_conf,\n",
    "    bidirectional=bidirectional\n",
    ")\n",
    "\n",
    "# Load your pretrained model weights\n",
    "model_path = \"/content/drive/MyDrive/advanced-machine-learning/best_model.bin\"\n",
    "state_dict = torch.load(model_path, map_location='cpu')\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "# Instantiate the decoder\n",
    "decoder = GreedyDecoder(LABELS)\n",
    "\n",
    "# Specify the path to the audio file you want to test\n",
    "audio_file = \"/content/drive/MyDrive/advanced-machine-learning/final4.wav\"\n",
    "\n",
    "# Load and preprocess the audio\n",
    "spect = load_audio(audio_file, sample_rate=audio_conf['sample_rate'])\n",
    "inputs = prepare_input_tensor(spect)\n",
    "input_lengths = torch.IntTensor([inputs.size(3)])\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    outputs, output_sizes = model(inputs, input_lengths)\n",
    "\n",
    "# Decode\n",
    "decoded_output, _ = decoder.decode(outputs, output_sizes)\n",
    "transcribed_text = decoded_output[0][0]\n",
    "\n",
    "print(\"Transcribed Text:\", transcribed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 2677,
     "status": "ok",
     "timestamp": 1734005885938,
     "user": {
      "displayName": "Liew Cheah Ming",
      "userId": "16761576291408548451"
     },
     "user_tz": -480
    },
    "id": "5hVK-kcriQgY",
    "outputId": "8781b737-dd2a-4fae-a3e1-a7c64d05475f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">655,616</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">196,864</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">296,448</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">61,824</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │           \u001b[38;5;34m4,096\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │           \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m512\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │         \u001b[38;5;34m655,616\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │         \u001b[38;5;34m196,864\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │           \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │         \u001b[38;5;34m296,448\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m256\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m61,824\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m520\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,704,026</span> (14.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,704,026\u001b[0m (14.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,233,992</span> (4.71 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,233,992\u001b[0m (4.71 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> (8.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,048\u001b[0m (8.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,467,986</span> (9.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,467,986\u001b[0m (9.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b833800c790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "[[2.3495150e-04 2.2222779e-09 9.9964249e-01 5.8524306e-06 4.4477896e-05\n",
      "  4.2014952e-05 2.9816256e-05 3.3385902e-07]]\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "# Load model configuration\n",
    "with open(\"/content/drive/MyDrive/advanced-machine-learning/best_model.keras/config.json\", \"r\") as json_file:\n",
    "    model_config = json_file.read()\n",
    "\n",
    "# Recreate the model architecture\n",
    "model = model_from_json(model_config)\n",
    "\n",
    "# Load the weights\n",
    "model.load_weights(\"/content/drive/MyDrive/advanced-machine-learning/best_model.keras/model.weights.h5\")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "audio_path = \"/content/drive/MyDrive/advanced-machine-learning/final4.wav\"\n",
    "audio_data, _ = librosa.load(audio_path, sr=16000) # Replace 16000 with your model's expected sample rate\n",
    "input_data = np.expand_dims(audio_data, axis=0)  # Add batch dimension\n",
    "\n",
    "# Assuming input_data is preprocessed\n",
    "predictions = model.predict(input_data)\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sEz_gZI6eECl"
   },
   "source": [
    "labels = ['neutral', 'calm', 'sad', 'happy', 'fear', 'disgust', 'surprise', 'angry']\n",
    "\n",
    "According to the prediction received above,  we have [[2.3495150e-04 2.2222779e-09 9.9964249e-01 5.8524306e-06 4.4477896e-05\r\n",
    "  4.2014952e-05 2.9816256e-05 3.3385902e-07] and the maximum value is of 9.9964249e-01 which is index 2. Which means the prediction is SAD\n",
    "  Which means it has succesfully predicted the speech]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNJxL1rfvYY5tfDYdNlMLSg",
   "mount_file_id": "1wk7peCngr1R0GTzfL72urL3amqKvYm8Z",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
